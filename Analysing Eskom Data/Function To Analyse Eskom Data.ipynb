{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38332bit95cab9994d5d4ce8b2760e46dd966f88",
   "display_name": "Python 3.8.3 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions That Will Be Used To Analyse Data\n",
    "\n",
    "Functions are important in reducing the replication of code as well as giving the user the functionality of getting an ouput on varying inputs. The functions below use Eskom data/variables.\n",
    "\n",
    "These functions are:\n",
    "\n",
    "Metric Dictionary\n",
    "Five Number Summary Dictionary\n",
    "Date Parser\n",
    "Hashtag & Municipality Remover\n",
    "Number of Tweets per Day\n",
    "Word Splitter\n",
    "Stopwords & Link Remover\n",
    "\n",
    "uthors: Nthabeleng Vilakazi, Refiloe Phipha, Neliswe Mabanga, Jaganeth Chetty and Sevha Vukeya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electricification by province (EBP) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  Financial Year (1 April - 30 March)  Limpopo  Mpumalanga  North west  \\\n0                              2000/1    51860       28365       48429   \n1                              2001/2    68121       26303       38685   \n2                              2002/3    49881       11976       28532   \n3                              2003/4    42034       33515       34027   \n4                              2004/5    54646       16218       21450   \n\n   Free State  Kwazulu Natal  Eastern Cape  Western Cape  Northern Cape  \\\n0       21293          63413         49008         48429           6168   \n1       20928          64123         45773         38685          10359   \n2       10316          63078         55748         28532           6869   \n3       16135          60282         47414         34027          10976   \n4        5668          37811         42041         21450           6316   \n\n   Gauteng  \n0    39660  \n1    36024  \n2    32127  \n3    39488  \n4    18422  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Financial Year (1 April - 30 March)</th>\n      <th>Limpopo</th>\n      <th>Mpumalanga</th>\n      <th>North west</th>\n      <th>Free State</th>\n      <th>Kwazulu Natal</th>\n      <th>Eastern Cape</th>\n      <th>Western Cape</th>\n      <th>Northern Cape</th>\n      <th>Gauteng</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2000/1</td>\n      <td>51860</td>\n      <td>28365</td>\n      <td>48429</td>\n      <td>21293</td>\n      <td>63413</td>\n      <td>49008</td>\n      <td>48429</td>\n      <td>6168</td>\n      <td>39660</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2001/2</td>\n      <td>68121</td>\n      <td>26303</td>\n      <td>38685</td>\n      <td>20928</td>\n      <td>64123</td>\n      <td>45773</td>\n      <td>38685</td>\n      <td>10359</td>\n      <td>36024</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2002/3</td>\n      <td>49881</td>\n      <td>11976</td>\n      <td>28532</td>\n      <td>10316</td>\n      <td>63078</td>\n      <td>55748</td>\n      <td>28532</td>\n      <td>6869</td>\n      <td>32127</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2003/4</td>\n      <td>42034</td>\n      <td>33515</td>\n      <td>34027</td>\n      <td>16135</td>\n      <td>60282</td>\n      <td>47414</td>\n      <td>34027</td>\n      <td>10976</td>\n      <td>39488</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2004/5</td>\n      <td>54646</td>\n      <td>16218</td>\n      <td>21450</td>\n      <td>5668</td>\n      <td>37811</td>\n      <td>42041</td>\n      <td>21450</td>\n      <td>6316</td>\n      <td>18422</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "ebp_url = 'https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/electrification_by_province.csv'\n",
    "ebp_df = pd.read_csv(ebp_url)\n",
    "\n",
    "for col, row in ebp_df.iloc[:,1:].iteritems():\n",
    "    ebp_df[col] = ebp_df[col].str.replace(',','').astype(int)\n",
    "\n",
    "ebp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                              Tweets                 Date\n0  @BongaDlulane Please send an email to mediades...  2019-11-29 12:50:54\n1         @saucy_mamiie Pls log a call on 0860037566  2019-11-29 12:46:53\n2       @BongaDlulane Query escalated to media desk.  2019-11-29 12:46:10\n3  Before leaving the office this afternoon, head...  2019-11-29 12:33:36\n4  #ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...  2019-11-29 12:17:43",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweets</th>\n      <th>Date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@BongaDlulane Please send an email to mediades...</td>\n      <td>2019-11-29 12:50:54</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@saucy_mamiie Pls log a call on 0860037566</td>\n      <td>2019-11-29 12:46:53</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@BongaDlulane Query escalated to media desk.</td>\n      <td>2019-11-29 12:46:10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Before leaving the office this afternoon, head...</td>\n      <td>2019-11-29 12:33:36</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>#ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...</td>\n      <td>2019-11-29 12:17:43</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "twitter_url = 'https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/twitter_nov_2019.csv'\n",
    "twitter_df = pd.read_csv(twitter_url)\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gauteng ebp data as a list\n",
    "gauteng = ebp_df['Gauteng'].astype(float).to_list()\n",
    "\n",
    "# dates for twitter tweets\n",
    "dates = twitter_df['Date'].to_list()\n",
    "\n",
    "# dictionary mapping official municipality twitter handles to the municipality name\n",
    "mun_dict = {\n",
    "    '@CityofCTAlerts' : 'Cape Town',\n",
    "    '@CityPowerJhb' : 'Johannesburg',\n",
    "    '@eThekwiniM' : 'eThekwini' ,\n",
    "    '@EMMInfo' : 'Ekurhuleni',\n",
    "    '@centlecutility' : 'Mangaung',\n",
    "    '@NMBmunicipality' : 'Nelson Mandela Bay',\n",
    "    '@CityTshwane' : 'Tshwane'\n",
    "}\n",
    "\n",
    "# dictionary of english stopwords\n",
    "stop_words_dict = {\n",
    "    'stopwords':[\n",
    "        'where', 'done', 'if', 'before', 'll', 'very', 'keep', 'something', 'nothing', 'thereupon', \n",
    "        'may', 'why', 'â€™s', 'therefore', 'you', 'with', 'towards', 'make', 'really', 'few', 'former', \n",
    "        'during', 'mine', 'do', 'would', 'of', 'off', 'six', 'yourself', 'becoming', 'through', \n",
    "        'seeming', 'hence', 'us', 'anywhere', 'regarding', 'whole', 'down', 'seem', 'whereas', 'to', \n",
    "        'their', 'various', 'thereafter', 'â€˜d', 'above', 'put', 'sometime', 'moreover', 'whoever', 'although', \n",
    "        'at', 'four', 'each', 'among', 'whatever', 'any', 'anyhow', 'herein', 'become', 'last', 'between', 'still', \n",
    "        'was', 'almost', 'twelve', 'used', 'who', 'go', 'not', 'enough', 'well', 'â€™ve', 'might', 'see', 'whose', \n",
    "        'everywhere', 'yourselves', 'across', 'myself', 'further', 'did', 'then', 'is', 'except', 'up', 'take', \n",
    "        'became', 'however', 'many', 'thence', 'onto', 'â€˜m', 'my', 'own', 'must', 'wherein', 'elsewhere', 'behind', \n",
    "        'becomes', 'alone', 'due', 'being', 'neither', 'a', 'over', 'beside', 'fifteen', 'meanwhile', 'upon', 'next', \n",
    "        'forty', 'what', 'less', 'and', 'please', 'toward', 'about', 'below', 'hereafter', 'whether', 'yet', 'nor', \n",
    "        'against', 'whereupon', 'top', 'first', 'three', 'show', 'per', 'five', 'two', 'ourselves', 'whenever', \n",
    "        'get', 'thereby', 'noone', 'had', 'now', 'everyone', 'everything', 'nowhere', 'ca', 'though', 'least', \n",
    "        'so', 'both', 'otherwise', 'whereby', 'unless', 'somewhere', 'give', 'formerly', 'â€™d', 'under', \n",
    "        'while', 'empty', 'doing', 'besides', 'thus', 'this', 'anyone', 'its', 'after', 'bottom', 'call', \n",
    "        'nâ€™t', 'name', 'even', 'eleven', 'by', 'from', 'when', 'or', 'anyway', 'how', 'the', 'all', \n",
    "        'much', 'another', 'since', 'hundred', 'serious', 'â€˜ve', 'ever', 'out', 'full', 'themselves', \n",
    "        'been', 'in', \"'d\", 'wherever', 'part', 'someone', 'therein', 'can', 'seemed', 'hereby', 'others', \n",
    "        \"'s\", \"'re\", 'most', 'one', \"n't\", 'into', 'some', 'will', 'these', 'twenty', 'here', 'as', 'nobody', \n",
    "        'also', 'along', 'than', 'anything', 'he', 'there', 'does', 'we', 'â€™ll', 'latterly', 'are', 'ten', \n",
    "        'hers', 'should', 'they', 'â€˜s', 'either', 'am', 'be', 'perhaps', 'â€™re', 'only', 'namely', 'sixty', \n",
    "        'made', \"'m\", 'always', 'those', 'have', 'again', 'her', 'once', 'ours', 'herself', 'else', 'has', 'nine', \n",
    "        'more', 'sometimes', 'your', 'yours', 'that', 'around', 'his', 'indeed', 'mostly', 'cannot', 'â€˜ll', 'too', \n",
    "        'seems', 'â€™m', 'himself', 'latter', 'whither', 'amount', 'other', 'nevertheless', 'whom', 'for', 'somehow', \n",
    "        'beforehand', 'just', 'an', 'beyond', 'amongst', 'none', \"'ve\", 'say', 'via', 'but', 'often', 're', 'our', \n",
    "        'because', 'rather', 'using', 'without', 'throughout', 'on', 'she', 'never', 'eight', 'no', 'hereupon', \n",
    "        'them', 'whereafter', 'quite', 'which', 'move', 'thru', 'until', 'afterwards', 'fifty', 'i', 'itself', 'nâ€˜t',\n",
    "        'him', 'could', 'front', 'within', 'â€˜re', 'back', 'such', 'already', 'several', 'side', 'whence', 'me', \n",
    "        'same', 'were', 'it', 'every', 'third', 'together'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 1: Metric Dictionary\n",
    "\n",
    "This function calculates the mean, median, variance, standard deviation, minimum and maximum of of list of items. You can assume the given list is contains only numerical entries.\n",
    "\n",
    "**Function Specifications:**\n",
    "- Function should allow a list as input.\n",
    "- It should return a `dict` with keys `'mean'`, `'median'`, `'std'`, `'var'`, `'min'`, and `'max'`, corresponding to the mean, median, standard deviation, variance, minimum and maximum of the input list, respectively.\n",
    "- The standard deviation and variance values must be unbiased. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'mean': 26244.416666666668,\n 'median': 24403.5,\n 'variance': 108160153.1742424,\n 'standard deviation': 10400.007364143663,\n 'min': 8842.0,\n 'max': 39660.0}"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "def dictionary_of_metrics(items):\n",
    "    # calculating mean\n",
    "    total = 0\n",
    "    for i in items:\n",
    "        total += i\n",
    "    mean = total/len(items)\n",
    "    \n",
    "    # maximum\n",
    "    maximum = items[0]\n",
    "    for i in items:\n",
    "        if i > maximum:\n",
    "            maximum = i\n",
    "    \n",
    "    # minimum\n",
    "    minimum = items[0]\n",
    "    for i in items:\n",
    "        if i < minimum:\n",
    "            minimum = i\n",
    "    \n",
    "    #median\n",
    "    for i in range(len(items)):\n",
    "        for k in range(len(items)-i-1):\n",
    "            if items[k]>items[k+1]:\n",
    "                items[k],items[k+1] = items[k+1],items[k]\n",
    "     \n",
    "    index_median = int((len(items)+1)/2)\n",
    "    if len(items)%2 == 0:\n",
    "        median = (items[index_median]+items[index_median-1])/2\n",
    "    else:\n",
    "        median = items[index_median]\n",
    "    \n",
    "    #variance\n",
    "    some = 0\n",
    "    for i in items:\n",
    "        whole = (i-mean)**2\n",
    "        some += whole\n",
    "    var = some/(len(items)-1)\n",
    "    \n",
    "    #standard deviation\n",
    "    std = var**0.5\n",
    "    \n",
    "    dict_word = {'mean':mean,\n",
    "                 'median' : median,\n",
    "                 'variance' :var,\n",
    "                 'standard deviation': std,\n",
    "                 'min': minimum,\n",
    "                 'max': maximum\n",
    "                 }\n",
    "    return dict_word\n",
    "dictionary_of_metrics(gauteng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 2: Five Number Summary\n",
    "\n",
    "This function takes in a list of integers and returns a dictionary of the [five number summary.](https://www.statisticshowto.datasciencecentral.com/how-to-find-a-five-number-summary-in-statistics/).\n",
    "\n",
    "**Function Specifications:**\n",
    "- The function should take a list as input.\n",
    "- The function should return a `dict` with keys `'max'`, `'median'`, `'min'`, `'q1'`, and `'q3'` corresponding to the maximum, median, minimum, first quartile and third quartile, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def five_num_summary(items):\n",
    "    # your code here\n",
    "    return {'max': np.max(items), 'median': np.median(items), 'min': np.min(items), 'q1': np.percentile(items, 25), 'q3': np.percentile(items, 75)}\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'max': 39660.0,\n 'median': 24403.5,\n 'min': 8842.0,\n 'q1': 18653.0,\n 'q3': 36372.0}"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "five_num_summary(gauteng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 3: Date Parser\n",
    "\n",
    "The `dates` variable (created at the top of this notebook) is a list of dates represented as strings. The string contains the date in `'yyyy-mm-dd'` format, as well as the time in `hh:mm:ss` formamt. The first three entries in this variable are:\n",
    "```python\n",
    "dates[:3] == [\n",
    "    '2019-11-29 12:50:54',\n",
    "    '2019-11-29 12:46:53',\n",
    "    '2019-11-29 12:46:10'\n",
    "]\n",
    "```\n",
    "\n",
    "The function below takes as input a list of these datetime strings and returns only the date in `'yyyy-mm-dd'` format.\n",
    "\n",
    "**Function Specifications:**\n",
    "- The function should take a list of strings as input.\n",
    "- Each string in the input list is formatted as `'yyyy-mm-dd hh:mm:ss'`.\n",
    "- The function should return a list of strings where each element in the returned list contains only the date in the `'yyyy-mm-dd'` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def date_parser(dates):\n",
    "    # your code here\n",
    "    dates_only =[]\n",
    "    for i in dates:\n",
    "        date = i[0:10]\n",
    "        dates_only.append(date)   \n",
    "    return dates_only\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['2019-11-29', '2019-11-29', '2019-11-29']"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "date_parser(dates[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 4: Municipality & Hashtag Detector\n",
    "\n",
    "This function takes in a pandas dataframe and returns a modified dataframe that includes two new columns that contain information about the municipality and hashtag of the tweet.\n",
    "\n",
    "**Function Specifications:**\n",
    "* Function should take a pandas `dataframe` as input.\n",
    "* Extract the municipality from a tweet using the `mun_dict` dictonary given below, and insert the result into a new column named `'municipality'` in the same dataframe.\n",
    "* Use the entry `np.nan` when a municipality is not found.\n",
    "* Extract a list of hashtags from a tweet into a new column named `'hashtags'` in the same dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def extract_municipality_hashtags(df):\n",
    "    # your code here\n",
    "    muni = list(mun_dict.keys())\n",
    "    df1 = df.copy()\n",
    "    cities = []\n",
    "    hashtags = []\n",
    "    \n",
    "    Tweets = list(df1['Tweets']) # Place Tweets in List\n",
    "    Tweets_Split = [] # Empty List for appending lists of words for each tweet\n",
    "    for Tweet in Tweets: # Loop to go through every Tweet in list\n",
    "        Tweets_Split.append(Tweet.lower().split()) # Append the split words to empty list created above\n",
    "    \n",
    "    for tweet in Tweets_Split: # Go to each tweet in the split words list\n",
    "        city1 = '' # Create empty string to store city names\n",
    "        hashs = [] # Create list to store Hastags per tweet\n",
    "        for words in tweet: # Goto each word in the tweet\n",
    "            if words in muni: # if word is in Municipality Dict Keys \n",
    "                city1 = str(mun_dict[words]) # Then Store the City for the key\n",
    "            if '#' in words: # if word contains a Hashtag\n",
    "                words = words.lower() # Store Word as lower case\n",
    "                hashs.append(words) # append word to list of hashs for that tweet\n",
    "        cities.append(city1) # Store city Name and append to list for each tweet\n",
    "        hashtags.append(hashs) # Store hastags per tweet and append to list\n",
    "    \n",
    "    cities = [np.nan if x == '' else x for x in cities] # Replace empty string with np.nan\n",
    "    df1['municipality'] = cities # Insert\n",
    "    df1['hashtags'] = hashtags #Insert\n",
    "    df1['hashtags'] = df1['hashtags'].apply(lambda y: np.nan if len(y)==0 else y) # Replace empty lists(no hashtags) with np.nan\n",
    "    \n",
    "    return df1 \n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                Tweets                 Date  \\\n0    @BongaDlulane Please send an email to mediades...  2019-11-29 12:50:54   \n1           @saucy_mamiie Pls log a call on 0860037566  2019-11-29 12:46:53   \n2         @BongaDlulane Query escalated to media desk.  2019-11-29 12:46:10   \n3    Before leaving the office this afternoon, head...  2019-11-29 12:33:36   \n4    #ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...  2019-11-29 12:17:43   \n..                                                 ...                  ...   \n195  Eskom's Visitors Centres’ facilities include i...  2019-11-20 10:29:07   \n196  #Eskom connected 400 houses and in the process...  2019-11-20 10:25:20   \n197       @ArthurGodbeer Is the power restored as yet?  2019-11-20 10:07:59   \n198  @MuthambiPaulina @SABCNewsOnline @IOL @eNCA @e...  2019-11-20 10:07:41   \n199  RT @GP_DHS: The @GautengProvince made a commit...  2019-11-20 10:00:09   \n\n     municipality                              hashtags  \n0             NaN                                   NaN  \n1             NaN                                   NaN  \n2             NaN                                   NaN  \n3             NaN                                   NaN  \n4             NaN    [#eskomfreestate, #mediastatement]  \n..            ...                                   ...  \n195           NaN                                   NaN  \n196           NaN  [#eskom, #eskom, #poweringyourworld]  \n197           NaN                                   NaN  \n198           NaN                                   NaN  \n199           NaN                                   NaN  \n\n[200 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweets</th>\n      <th>Date</th>\n      <th>municipality</th>\n      <th>hashtags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@BongaDlulane Please send an email to mediades...</td>\n      <td>2019-11-29 12:50:54</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@saucy_mamiie Pls log a call on 0860037566</td>\n      <td>2019-11-29 12:46:53</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@BongaDlulane Query escalated to media desk.</td>\n      <td>2019-11-29 12:46:10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Before leaving the office this afternoon, head...</td>\n      <td>2019-11-29 12:33:36</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>#ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...</td>\n      <td>2019-11-29 12:17:43</td>\n      <td>NaN</td>\n      <td>[#eskomfreestate, #mediastatement]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>Eskom's Visitors Centres’ facilities include i...</td>\n      <td>2019-11-20 10:29:07</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>#Eskom connected 400 houses and in the process...</td>\n      <td>2019-11-20 10:25:20</td>\n      <td>NaN</td>\n      <td>[#eskom, #eskom, #poweringyourworld]</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>@ArthurGodbeer Is the power restored as yet?</td>\n      <td>2019-11-20 10:07:59</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>@MuthambiPaulina @SABCNewsOnline @IOL @eNCA @e...</td>\n      <td>2019-11-20 10:07:41</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>RT @GP_DHS: The @GautengProvince made a commit...</td>\n      <td>2019-11-20 10:00:09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "extract_municipality_hashtags(twitter_df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 5: Number of Tweets per Day\n",
    "\n",
    "This function calculates the number of tweets that were posted per day. \n",
    "\n",
    "**Function Specifications:**\n",
    "- It should take a pandas dataframe as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def number_of_tweets_per_day(df):\n",
    "    # your code here\n",
    "    df1 = df.copy() # Make a Copy Of DataFrame\n",
    "    dates = list(df1['Date']) # Extract List of Dates from Copied Dataframe\n",
    "    dates_only = [] # Intialize empty list to store only dates from datetime strings\n",
    "    for date in dates: # Start loop - Loop through every datetime in list called dates\n",
    "        temp = date[0:10] # Extract only date from datetime\n",
    "        dates_only.append(temp) # Append each date in loop to empty list intialized above\n",
    "        \n",
    "    data = pd.DataFrame() # Create empty Dataframe called data\n",
    "    data['Date'] = dates_only # Input Dates in First Column\n",
    "    data['Tweets'] = 1 # Input Column containing only 1's for groupyby sum\n",
    "    data = data.groupby(['Date']).sum() # Grouby Date and get sum of Tweets per Date\n",
    "    return data\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            Tweets\nDate              \n2019-11-20      18\n2019-11-21      11\n2019-11-22      25\n2019-11-23      19\n2019-11-24      14\n2019-11-25      20\n2019-11-26      32\n2019-11-27      13\n2019-11-28      32\n2019-11-29      16",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweets</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-11-20</th>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>2019-11-21</th>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2019-11-22</th>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>2019-11-23</th>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>2019-11-24</th>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>2019-11-25</th>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2019-11-26</th>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>2019-11-27</th>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>2019-11-28</th>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>2019-11-29</th>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "number_of_tweets_per_day(twitter_df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 6: Word Splitter\n",
    "\n",
    "This function splits the sentences in a dataframe's column into a list of the separate words. The created lists should be placed in a column named `'Split Tweets'` in the original dataframe. This is also known as [tokenization](https://www.geeksforgeeks.org/nlp-how-tokenizing-text-sentence-words-works/).\n",
    "\n",
    "**Function Specifications:**\n",
    "- It should take a pandas dataframe as an input.\n",
    "- The dataframe should contain a column, named `'Tweets'`.\n",
    "- The function should split the sentences in the `'Tweets'` into a list of seperate words, and place the result into a new column named `'Split Tweets'`. The resulting words must all be lowercase!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def word_splitter(df):\n",
    "    # your code here\n",
    "    df1 = df.copy() # Make Copy Of Dataframe\n",
    "    Tweets = list(df1['Tweets']) # Place Tweets in List\n",
    "    Tweets_Split = [] # Empty List for appending lists of words for each tweet\n",
    "    for Tweet in Tweets: # Loop to go through every Tweet in list\n",
    "        Tweets_Split.append(Tweet.lower().split()) # Append the split words to empty list created above\n",
    "    df1['Split Tweets'] = Tweets_Split # Insert list of lists where sublists contain splitwords into dataframe\n",
    "    return df1\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                Tweets                 Date  \\\n0    @BongaDlulane Please send an email to mediades...  2019-11-29 12:50:54   \n1           @saucy_mamiie Pls log a call on 0860037566  2019-11-29 12:46:53   \n2         @BongaDlulane Query escalated to media desk.  2019-11-29 12:46:10   \n3    Before leaving the office this afternoon, head...  2019-11-29 12:33:36   \n4    #ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...  2019-11-29 12:17:43   \n..                                                 ...                  ...   \n195  Eskom's Visitors Centres’ facilities include i...  2019-11-20 10:29:07   \n196  #Eskom connected 400 houses and in the process...  2019-11-20 10:25:20   \n197       @ArthurGodbeer Is the power restored as yet?  2019-11-20 10:07:59   \n198  @MuthambiPaulina @SABCNewsOnline @IOL @eNCA @e...  2019-11-20 10:07:41   \n199  RT @GP_DHS: The @GautengProvince made a commit...  2019-11-20 10:00:09   \n\n                                          Split Tweets  \n0    [@bongadlulane, please, send, an, email, to, m...  \n1    [@saucy_mamiie, pls, log, a, call, on, 0860037...  \n2    [@bongadlulane, query, escalated, to, media, d...  \n3    [before, leaving, the, office, this, afternoon...  \n4    [#eskomfreestate, #mediastatement, :, eskom, s...  \n..                                                 ...  \n195  [eskom's, visitors, centres’, facilities, incl...  \n196  [#eskom, connected, 400, houses, and, in, the,...  \n197  [@arthurgodbeer, is, the, power, restored, as,...  \n198  [@muthambipaulina, @sabcnewsonline, @iol, @enc...  \n199  [rt, @gp_dhs:, the, @gautengprovince, made, a,...  \n\n[200 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweets</th>\n      <th>Date</th>\n      <th>Split Tweets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@BongaDlulane Please send an email to mediades...</td>\n      <td>2019-11-29 12:50:54</td>\n      <td>[@bongadlulane, please, send, an, email, to, m...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@saucy_mamiie Pls log a call on 0860037566</td>\n      <td>2019-11-29 12:46:53</td>\n      <td>[@saucy_mamiie, pls, log, a, call, on, 0860037...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@BongaDlulane Query escalated to media desk.</td>\n      <td>2019-11-29 12:46:10</td>\n      <td>[@bongadlulane, query, escalated, to, media, d...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Before leaving the office this afternoon, head...</td>\n      <td>2019-11-29 12:33:36</td>\n      <td>[before, leaving, the, office, this, afternoon...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>#ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...</td>\n      <td>2019-11-29 12:17:43</td>\n      <td>[#eskomfreestate, #mediastatement, :, eskom, s...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>Eskom's Visitors Centres’ facilities include i...</td>\n      <td>2019-11-20 10:29:07</td>\n      <td>[eskom's, visitors, centres’, facilities, incl...</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>#Eskom connected 400 houses and in the process...</td>\n      <td>2019-11-20 10:25:20</td>\n      <td>[#eskom, connected, 400, houses, and, in, the,...</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>@ArthurGodbeer Is the power restored as yet?</td>\n      <td>2019-11-20 10:07:59</td>\n      <td>[@arthurgodbeer, is, the, power, restored, as,...</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>@MuthambiPaulina @SABCNewsOnline @IOL @eNCA @e...</td>\n      <td>2019-11-20 10:07:41</td>\n      <td>[@muthambipaulina, @sabcnewsonline, @iol, @enc...</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>RT @GP_DHS: The @GautengProvince made a commit...</td>\n      <td>2019-11-20 10:00:09</td>\n      <td>[rt, @gp_dhs:, the, @gautengprovince, made, a,...</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "word_splitter(twitter_df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 7: Stop Words\n",
    "\n",
    "This function removes english stop words from a tweet.\n",
    "\n",
    "**Function Specifications:**\n",
    "- It should take a pandas dataframe as input.\n",
    "- The function should modify the input dataframe.\n",
    "- The function should return the modified dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def stop_words_remover(df):\n",
    "    # your code here\n",
    "    Tweets_new = []  #empty list to store tweets\n",
    "    Tweets = list(df['Tweets']) #store tweets in the list\n",
    "    Tweets_Split = [] #Empty List for appending lists of words for each tweet\n",
    "    for Tweet in Tweets: #Loop to go through each an every Tweet in list\n",
    "        Tweets_Split.append(Tweet.lower().split()) # Append the split words to empty list created above\n",
    "        for Tweets in Tweets_Split: # Loop to through each tweet in split tweets list\n",
    "            x = Tweets\n",
    "            for item in x: # Go through each item in each tweet\n",
    "                if item in stop_words_dict['stopwords']: # Chech if item is in stopwords dictionary\n",
    "                    x.remove(item) # if it is remove the item from list of split words per tweets\n",
    "        Tweets_new.append(x)      \n",
    "    df['Without Stop Words'] = Tweets_new # Insert list of lists where sublists contain splitwords without stopwords into dataframe\n",
    "    return df\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                Tweets                 Date  \\\n0    @BongaDlulane Please send an email to mediades...  2019-11-29 12:50:54   \n1           @saucy_mamiie Pls log a call on 0860037566  2019-11-29 12:46:53   \n2         @BongaDlulane Query escalated to media desk.  2019-11-29 12:46:10   \n3    Before leaving the office this afternoon, head...  2019-11-29 12:33:36   \n4    #ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...  2019-11-29 12:17:43   \n..                                                 ...                  ...   \n195  Eskom's Visitors Centres’ facilities include i...  2019-11-20 10:29:07   \n196  #Eskom connected 400 houses and in the process...  2019-11-20 10:25:20   \n197       @ArthurGodbeer Is the power restored as yet?  2019-11-20 10:07:59   \n198  @MuthambiPaulina @SABCNewsOnline @IOL @eNCA @e...  2019-11-20 10:07:41   \n199  RT @GP_DHS: The @GautengProvince made a commit...  2019-11-20 10:00:09   \n\n                                    Without Stop Words  \n0    [@bongadlulane, send, email, mediadesk@eskom.c...  \n1                [@saucy_mamiie, pls, log, 0860037566]  \n2      [@bongadlulane, query, escalated, media, desk.]  \n3    [leaving, office, afternoon,, heading, weekend...  \n4    [#eskomfreestate, #mediastatement, :, eskom, s...  \n..                                                 ...  \n195  [eskom's, visitors, centres’, facilities, incl...  \n196  [#eskom, connected, 400, houses, process, conn...  \n197            [@arthurgodbeer, power, restored, yet?]  \n198  [@muthambipaulina, @sabcnewsonline, @iol, @enc...  \n199  [rt, @gp_dhs:, @gautengprovince, a, commitment...  \n\n[200 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweets</th>\n      <th>Date</th>\n      <th>Without Stop Words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@BongaDlulane Please send an email to mediades...</td>\n      <td>2019-11-29 12:50:54</td>\n      <td>[@bongadlulane, send, email, mediadesk@eskom.c...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@saucy_mamiie Pls log a call on 0860037566</td>\n      <td>2019-11-29 12:46:53</td>\n      <td>[@saucy_mamiie, pls, log, 0860037566]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@BongaDlulane Query escalated to media desk.</td>\n      <td>2019-11-29 12:46:10</td>\n      <td>[@bongadlulane, query, escalated, media, desk.]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Before leaving the office this afternoon, head...</td>\n      <td>2019-11-29 12:33:36</td>\n      <td>[leaving, office, afternoon,, heading, weekend...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>#ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...</td>\n      <td>2019-11-29 12:17:43</td>\n      <td>[#eskomfreestate, #mediastatement, :, eskom, s...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>Eskom's Visitors Centres’ facilities include i...</td>\n      <td>2019-11-20 10:29:07</td>\n      <td>[eskom's, visitors, centres’, facilities, incl...</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>#Eskom connected 400 houses and in the process...</td>\n      <td>2019-11-20 10:25:20</td>\n      <td>[#eskom, connected, 400, houses, process, conn...</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>@ArthurGodbeer Is the power restored as yet?</td>\n      <td>2019-11-20 10:07:59</td>\n      <td>[@arthurgodbeer, power, restored, yet?]</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>@MuthambiPaulina @SABCNewsOnline @IOL @eNCA @e...</td>\n      <td>2019-11-20 10:07:41</td>\n      <td>[@muthambipaulina, @sabcnewsonline, @iol, @enc...</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>RT @GP_DHS: The @GautengProvince made a commit...</td>\n      <td>2019-11-20 10:00:09</td>\n      <td>[rt, @gp_dhs:, @gautengprovince, a, commitment...</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "stop_words_remover(twitter_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}